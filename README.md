# ğŸ– Hand Gesture-Based System Controller

A real-time hand gesture recognition system that allows users to control **system volume** and **screen scrolling** using only their hand gestures. Built with **MediaPipe**, **scikit-learn**, and **OpenCV**, this lightweight Python project is suitable for productivity, accessibility enhancement, or fun gesture-based interaction demos.

---

## ğŸš€ Features

- âœ‹ Hand gesture recognition using Mediapipe (21 landmark points)
- ğŸ”Š Volume Up / Volume Down control via gestures
- â¬†ï¸â¬‡ï¸ Scroll Up / Scroll Down (useful in browsers, PDFs, etc.)
- ğŸ§  Trainable KNN model (`scikit-learn`) for user-defined gestures
- ğŸ¯ Modular design with easy-to-extend gesture mapping
- ğŸ’» Optional Jupyter notebook for retraining and experimentation

---

## ğŸ“ Folder Structure
```
Hand-Gesture-Based-System-Controller/
â”œâ”€â”€ src/ # Main real-time recognizer & system control logic
â”‚ â”œâ”€â”€ gesture_recognizer.py
â”‚ â””â”€â”€ system_control.py
â”œâ”€â”€ data/ # Gesture dataset CSV (optional upload)
â”‚ â””â”€â”€ gesture_data.csv
â”œâ”€â”€ models/ # Trained KNN + LabelEncoder
â”‚ â”œâ”€â”€ knn_model.joblib
â”‚ â””â”€â”€ label_encoder.joblib
â”œâ”€â”€ notebooks/ # Jupyter notebook for training
â”‚ â””â”€â”€ train_gesture_knn.ipynb
â”œâ”€â”€ record_gesture.py # Tool to record gestures to CSV
â”œâ”€â”€ requirements.txt # Project dependencies
â””â”€â”€ README.md
```
---

##  ğŸ”§ Supported Gestures

Gesture Label	Function
- volume_up	Increase system volume ğŸ”Š
- volume_down	Decrease system volume ğŸ”‰
- scroll_up	Scroll screen up â¬†ï¸
- scroll_down	Scroll screen down â¬‡ï¸

You can extend this list by modifying record_gesture.py, retraining the model, and updating system_control.py.

---

## ğŸ’¡ Future Ideas

- Add support for play/pause, next track, or screenshot with more gestures
- Port to Android using MediaPipe SDK + Kotlin
- Add WebUI to train gestures from browser
